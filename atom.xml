<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://bike.github.io/</id>
  <title>кракозя́бры</title>
  <updated>2017-02-16T22:19:09Z</updated>
  <link rel="alternate" href="https://bike.github.io/"/>
  <link rel="self" href="https://bike.github.io/atom.xml"/>
  <author>
    <name>None</name>
    <uri>https://bike.github.io</uri>
  </author>
  <entry>
    <id>tag:bike.github.io,2017-02-16:/posts/kildall.html</id>
    <title type="html">Kildall's algorithm</title>
    <published>2017-02-16T22:19:09Z</published>
    <updated>2017-02-16T22:19:09Z</updated>
    <link rel="alternate" href="https://bike.github.io/posts/kildall.html"/>
    <content type="html">
&lt;p&gt;Been a while. Life is busying.&lt;/p&gt;

&lt;p&gt;I got a part time job writing a Lisp compiler, so I’m going to talk about that.&lt;/p&gt;

&lt;p&gt;This post might be hard to understand if you do not program. Or if you do. There’s a fair amount of background required.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id="there-are-lisp-compilers"&gt;There are Lisp compilers?&lt;/h2&gt;

&lt;p&gt;You might be familiar with Lisp in the form of a Scheme interpreter you used for a few semesters in college. You might think things about it like “it’s so elegant, but it’s kind of impractical for day-to-day use”. You might think of it as “an interpreted language” and so don’t understand what I mean by Lisp compiler. If you don’t think these things you can probably skip to the next section.&lt;/p&gt;

&lt;p&gt;In Lisp, in contrast with some languages, the semantics are essentially built around interpretation. When you give a Lisp interpreter some code it goes through it step by step and executes it. This invites careful execution. It’s natural, for example, to expect that a program like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(defun foo (x) (+ x 237))
(foo "hello world")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;that defines an addition function and then calls it on a string, will do something nice like pop you into a debugger, rather than return garbage data.&lt;/p&gt;

&lt;p&gt;But it’s also generally slow. The interpreter has to do something on all possible input. It can’t, for instance, very well optimize FOO to accept only one numerical argument in a register, because later FOO might be called with a string.&lt;/p&gt;

&lt;p&gt;So you add a compiler. The compiler is an optimization. It takes code and returns an optimized version that tries to preserve these semantics as much as possible while being much faster. The optimized version is faster partly because it’s probably composed of machine code or JVM bytecode or something else interpretable very quickly, and partly because of higher level optimizations. For example&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(defun foo (x) (+ x 237))
(+ (foo 16) 93)
(mapcar (eval) '(3 898 38))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;here the compiler might note that FOO can only accept numbers, and when it sees a straightforward call to FOO like in the second line that gives it only numbers, it generates code that skips the “is this a number? No? Debugger time” check. An “interpreter stub” retains the whole safest behavior, and can be used in the third line if &lt;code&gt;eval&lt;/code&gt; returns FOO.&lt;/p&gt;

&lt;p&gt;This strikes a good balance, for me, between speed and freedom. The optimized code isn’t any less safe, so I can still write things with abandon and watch them fail in the debugger.&lt;/p&gt;

&lt;p&gt;The downside is that the compiler has to be pretty smart to be very effective. Luckily several Lisp implementations with pretty good compilers already exist, like SBCL and CCL. Both can generate fast&lt;sup id="fnref:fast"&gt;&lt;a href="#fn:fast" class="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; code without too much trouble.&lt;/p&gt;

&lt;h2 id="so-what-is-it-youre-doing"&gt;So what is it you’re doing&lt;/h2&gt;

&lt;p&gt;I work on a new Lisp compiler called Cleavir. Cleavir is the compiler part of Dr. Robert Strandh’s project, &lt;a href="https://github.com/robert-strandh/SICL"&gt;SICL&lt;/a&gt;. SICL is intended to provide modular, reusable, clean, and more positive adjectives code to other implementations, as well as being an implementation in itself.&lt;/p&gt;

&lt;p&gt;SICL isn’t yet an implementation on its own, but Cleavir is used in another new Lisp implementation, &lt;a href="https://github.com/drmeister/clasp"&gt;clasp&lt;/a&gt;, which is Dr. Christian Schafmeister’s project.&lt;/p&gt;

&lt;p&gt;As far as I know the initial thoughts for Clasp went something like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;drmeister&amp;gt; My lab has this new system for designing artificial protein-oids. They’re made of &lt;em&gt;bis&lt;/em&gt;-amino acids, which we also invented.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;DoD, etc. shadowy masters&amp;gt; Frikkin’ sweet.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;drmeister&amp;gt; We call them spiroligozymes&lt;sup id="fnref:spiro"&gt;&lt;a href="#fn:spiro" class="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. They could have incredible implications for-&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;DoD, etc.&amp;gt; Sure great. Here’s an award for being a literal nanotechnologist, named after that physicist everyone likes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;drmeister&amp;gt; OK so the thing is that this stuff we’re doing involves &lt;a href="http://dl.acm.org/citation.cfm?id=3005738"&gt;a lot of computer work&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;DoD, etc.&amp;gt; Because it’s the future.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;drmeister&amp;gt; Right, and we mostly do that in C++. But I like Lisp.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;DoD, etc.&amp;gt; Great. Use it. It’s got an ANSI standard. God bless America.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;drmeister&amp;gt; But we don’t want to lose the C++ code. Lisp can use C functions but C++ doesn’t really have any interoperability.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;DoD, etc.&amp;gt; So?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;drmeister&amp;gt; So I was thinking I’d spend several years making a new Lisp implementation that’s tight with C++ from the ground up.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;DoD, etc.&amp;gt; That sounds hard, and you’re a chemist.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;drmeister&amp;gt; So that’s a no, or…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&amp;lt;DoD, etc.&amp;gt; Here is a zillion dollars. Snap to it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It must be nice being a respectable scientist, is what I’m saying.&lt;/p&gt;

&lt;p&gt;Clasp ended up being based on Embeddable Common Lisp (ECL), so called because it’s written in C and designed to be called from C programs. ECL provides a lot of the runtime. For compilation, however, Cleavir compiles Lisp programs into its “Mid-level Intermediate Representation”, or MIR; Clasp then compiles this into LLVM-IR, which LLVM than compiles to machine code.&lt;/p&gt;

&lt;p&gt;This is pretty convoluted and presents some problems (LLVM doesn’t really seem to make itself a good target for something with an online compiler and mostly heap allocation, for one). Luckily they are not usually mine, because I mostly limit myself to Cleavir, but it’s nice to know the nature of the gnashing maw you hang over.&lt;/p&gt;

&lt;h2 id="hir"&gt;HIR&lt;/h2&gt;

&lt;p&gt;Cleavir’s MIR, and also HIR (“High-level”), are mostly what I work with. Consider this (silly) function:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(defun example (x)
  (flet ((getx () x)
         (setx (y) (setf x y)))
    (setx 19)
    (print (getx))
    (+ (getx) 331)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;flet&lt;/code&gt; establishes local closures, and &lt;code&gt;setf&lt;/code&gt; assigns. &lt;code&gt;(example anything)&lt;/code&gt; will print 19 and then return 350.&lt;/p&gt;

&lt;p&gt;In HIR, after a few transformations, the code looks like &lt;a href="../getx_setx.png"&gt;this&lt;/a&gt;. Here are the basics: white rectangles are “instructions”, and represent basic operations. Ovals and the orange rectangles are “data”. The solid black arrows indicate control flow. Red dashed arrows indicate inputs to instructions, and blue dashed arrows outputs. Functions begin with the instructions called “enter”.&lt;/p&gt;

&lt;p&gt;A few instruction explanations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;enter&lt;/code&gt; is the beginning of a function.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Create cell&lt;/code&gt;, &lt;code&gt;Write cell&lt;/code&gt;, &lt;code&gt;Fetch&lt;/code&gt;, and &lt;code&gt;Read cell&lt;/code&gt; have to do with shared variables for closures - more on that below.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;enclose&lt;/code&gt; allocates a closure. The regular inputs are (cells for) closed-over variables, while the input with the dashed pink line is the actual function code.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;funcall&lt;/code&gt; calls a function, the 1 input, with the other inputs as arguments.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ret&lt;/code&gt; returns values from a function.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It’s not really much different from any assembly-type language in form, other than having closures and explicitly separating input and output, but it’s more convenient to represent control flow graphically than with labels.&lt;/p&gt;

&lt;h2 id="the-algorithm"&gt;The algorithm&lt;/h2&gt;

&lt;p&gt;A graph of operation nodes is pretty common as an intermediate representation, because it maps closely with the conception of computers as state machines. As such, some optimization techniques are well-trodden.&lt;/p&gt;

&lt;p&gt;In 1973, G. A. Kildall published his paper &lt;a href="https://drona.csa.iisc.ernet.in/~deepakd/pav/kildall-popl73.pdf"&gt;“A Unified Approach to Global Program Optimization”&lt;/a&gt;&lt;sup id="fnref:ACM"&gt;&lt;a href="#fn:ACM" class="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. The title is a bit grandiose but actually pretty accurate. Kildall laid out a very general algorithm for associating optimization information of any kind with nodes in an instruction graph of this form. A few weeks ago I implemented it for Cleavir.&lt;/p&gt;

&lt;p&gt;It works like this. First, you establish some domain of optimization information. This domain can be anything you want, as long as it forms a bounded &lt;a href="https://en.wikipedia.org/wiki/Semilattice"&gt;meet-semilattice&lt;/a&gt;&lt;sup id="fnref:English"&gt;&lt;a href="#fn:English" class="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;. Elements of the domain are called “pools”. Next, you define an “optimization function” which, given an instruction node and its pool, returns another pool.&lt;/p&gt;

&lt;p&gt;The algorithm has a “work set” consisting of instructions paired with pools. The initial contents of the work set are dependent on what you’re doing, but contain at least one instruction. The algorithm returns what I’ve been calling a “dictionary”, which is an association of instructions to pools that is distinct from the work set. Initially the dictionary is empty, i.e. there are no associations.&lt;/p&gt;

&lt;p&gt;The algorithm proceeds by choosing and removing some (instruction, pool) pair from the work set. If the instruction removed has not yet been associated with a pool in the dictionary, or if the associated pool is less than or equal to (an operation established by the definition of meet) the pool from the work set, the instruction becomes associated with a new pool that is the meet of the old association and the pool from the work set. Additionally, the optimization function is called with the instruction and this new pool; the result pool is paired with all instructions immediate succeeding (or preceding, depending on what you’re doing) the instruction in the work set.&lt;/p&gt;

&lt;p&gt;But the paper describes that better. Intuitively, what happens is that if the pool in the work set for an instruction is “better” than the one for that instruction already in the dictionary, in some domain-specific sense, the instruction is reassociated with a “better” pool, and the nearby instructions are put in the work set with new information based on this instruction.&lt;/p&gt;

&lt;h2 id="examples"&gt;Examples&lt;/h2&gt;

&lt;p&gt;Nothing makes sense when it’s put that abstractly, right? It’s not just me? I don’t know how mathematicians survive.&lt;/p&gt;

&lt;p&gt;I implemented this algorithm in a general way. The function, &lt;code&gt;kildall&lt;/code&gt;, takes an argument called a “specialization” that includes all the domain-specific information for the algorithm. I have a few of these specializations.&lt;/p&gt;

&lt;p&gt;The one I just put into a usable state was escape analysis. Check out the program with &lt;code&gt;getx&lt;/code&gt; and &lt;code&gt;setx&lt;/code&gt; again. An interpreter, upon seeing the &lt;code&gt;flet&lt;/code&gt;, would allocate closures for both functions on the heap, i.e. dynamically, with cleanup being handled by the garbage collector. But if we look at the program, we can see that the closures cannot possibly be returned from this function or otherwise appear outside a strictly delimited context - they do not “escape”. In other words, these closures could be allocated with stack discipline. This is cheaper. An interpreter isn’t smart enough to see this but a compiler ought to be able to.&lt;/p&gt;

&lt;p&gt;To analyze this with Kildall, we can have it track &lt;em&gt;uses&lt;/em&gt; of values. A use causes an escape or does not; e.g. returning a value is an escape, but adding it is not. We define a pool as a map from variables to escape indicators. An indicator is &lt;em&gt;true&lt;/em&gt; if the variable escapes, and &lt;em&gt;false&lt;/em&gt; if it does not. Meet is a union of maps; if a variable appears in both maps, the new map’s indicator for that variable is the logical OR of the two indicators.&lt;sup id="fnref:pessimism"&gt;&lt;a href="#fn:pessimism" class="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt; The bound is a map where all variables are known to escape.&lt;/p&gt;

&lt;p&gt;The optimization function does different things depending on the type of instruction. We can do a completely correct, if overly conservative, analysis with the following rules:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Inputs to a RETURN instruction escape.&lt;/li&gt;
  &lt;li&gt;The first input to a FUNCALL instruction - the function called - does not escape.&lt;sup id="fnref:funcall"&gt;&lt;a href="#fn:funcall" class="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt; The other arguments are assumed to escape, because we don’t know what the function does.&lt;/li&gt;
  &lt;li&gt;All inputs to all other instructions escape.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The algorithm can then proceed in the reverse direction of control flow. &lt;a href="../getx_setx.png"&gt;Here’s the HIR again.&lt;/a&gt; We start at the bottom return instruction, with an initial pool of the empty map. The return is not yet associated with any pool, so it takes that one, and passes on a pool up where its input, the “V”, escapes.&lt;/p&gt;

&lt;p&gt;It proceeds upwards in that way and then reaches the funcall to which GETX is input. It’s the first input, i.e. the function called, and we have not seen GETX before, so we put (GETX, false) in the next pool up. The same occurs for the other funcall with GETX, and so once we reach the top instruction, we have that GETX does not escape, and can be stack allocated.&lt;/p&gt;

&lt;p&gt;The beautiful thing here is that all we actually need to have in the code are the definition of the semilattice and the optimization function rules, and the algorithm handles all the control flow. The analysis automatically works just as well around branches and loops. The whole thing is maybe fifty lines.&lt;/p&gt;

&lt;h2 id="extending-the-analysis"&gt;Extending the analysis&lt;/h2&gt;

&lt;p&gt;Stack allocating closures is nice, but what about those “cell” things? A cell is just a wrapper around a value, with a set and a get, like an ML “reference”. Closures in a language with assignment, like Lisp, have to have something like this; if &lt;code&gt;setx&lt;/code&gt; just closed over the value, the assignment to x would not take in the outer function. These cells are implicit in the source code but still have to be allocated.&lt;/p&gt;

&lt;p&gt;Determining that a cell can be stack allocated is more complicated. Naïvely, you might expect that a cell doesn’t escape if every closure it’s put in doesn’t escape. This is basically true, but there’s a nesting problem. Consider:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(lambda (x) ((lambda () (lambda () x))))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a function of one argument, which calls a function of zero arguments, which returns a function of no arguments that returns the first function’s argument. So for example if you call this function with x=4, you get back a function that returns 4.&lt;/p&gt;

&lt;p&gt;The HIR looks &lt;a href="../nested.png"&gt;like so&lt;/a&gt;. The outer function allocates a cell for x and a closure for the middle function using it, then calls that function. The middle function fetches the same, identical cell, puts it in a new closure for the innermost function, and then returns it.&lt;/p&gt;

&lt;p&gt;If we use the Kildall specialization described above in the outer function, it will determine, correctly, that the middle closure can be stack-allocated; if used on the middle function it will determine, also correctly, that the inner closure cannot.&lt;/p&gt;

&lt;p&gt;Were we to say that a cell doesn’t escape if everything it’s closed into, the outer function analysis would find, incorrectly, that the cell can be stack allocated - because it doesn’t know anything about the inner functions.&lt;/p&gt;

&lt;h2 id="extending-kildall"&gt;Extending Kildall&lt;/h2&gt;

&lt;p&gt;To determine whether cells can be stack allocated, we need to extend the algorithm to be aware of nested functions, which Kildall did not consider.&lt;/p&gt;

&lt;p&gt;The obvious thing to do is, when the algorithm hits an &lt;code&gt;enclose&lt;/code&gt; instruction, it calls for a recursive analysis on the inner function. This analysis can determine that the fetched cell is enclosed in a closure which escapes. Another step converts this analysis into a simplified “info” structure with only the information we need, i.e. whether the cells can escape the inner function. The optimization function for the outer &lt;code&gt;enclose&lt;/code&gt; then uses this information to determine that the cell escapes.&lt;/p&gt;

&lt;p&gt;On the &lt;code&gt;getx&lt;/code&gt; example, it can determine in this way that the cell for &lt;code&gt;x&lt;/code&gt; does &lt;em&gt;not&lt;/em&gt; escape, as the functions don’t return their cells or any closures. So the &lt;code&gt;x&lt;/code&gt; cell can be stack allocated there.&lt;/p&gt;

&lt;p&gt;That’s as far as I’ve actually implemented.&lt;/p&gt;

&lt;h2 id="future"&gt;Future&lt;/h2&gt;

&lt;p&gt;Earlier, I mentioned that arguments to a &lt;code&gt;funcall&lt;/code&gt; instruction other than the function called are assumed to escape. This is because the analysis does not know anything about the function called, and so cannot assume anything. However, as long as we’re analyzing inner functions, we have a representation for the information we need, the “info” structure. Particularly, we can track whether arguments are returned from functions (which does not inhibit them being stack-allocated in the calling function), or escape more generally. Then in the funcall we can use this information to provide a better analysis.&lt;/p&gt;

&lt;p&gt;The problem is that this information effectively has to be propagated &lt;em&gt;forward&lt;/em&gt; from the &lt;code&gt;enclose&lt;/code&gt; to the &lt;code&gt;funcall&lt;/code&gt;, i.e. in the opposite direction as this analysis. This propagation is not trivial. We could have code like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(lambda ()
  (flet ((foo (x) x)
         (bar (y) y)
         (baz ...))
    (funcall (if (some-condition) #'foo #'bar) #'baz)
    nil))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;baz&lt;/code&gt; can be stack-allocated, but knowing this requires knowing that both possibly called functions do not let their argument escape.&lt;/p&gt;

&lt;p&gt;It would be possible to tie in another Kildall specialization, type inference, to do this. Type inference propagates forward, and finds for each variable a set of values that it always contains. In the above, the implicit called-function variable always contains a function that does not let its argument escape.&lt;/p&gt;

&lt;p&gt;This implies that type inference would have to be aware of the escape analysis, and escape analysis of type inference. A principled way to compose different specializations of Kildall’s algorithm together would do it.&lt;/p&gt;

&lt;div class="footnotes"&gt;
  &lt;ol&gt;
    &lt;li id="fn:fast"&gt;
      &lt;p&gt;Which “languages” are “faster” is an argument I don’t want to get into. But if I spend comparable amounts of effort writing a program with clang, SBCL, and CPython, the SBCL program will probably be two to ten times as slow as clang’s, and a hundred to a thousand times as fast as CPython’s.&amp;nbsp;&lt;a href="#fnref:fast" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id="fn:spiro"&gt;
      &lt;p&gt;Check out this incredible title: &lt;a href="http://pubs.acs.org/doi/abs/10.1021/ja3069648"&gt;“Spiroligozymes for Transesterifications: Design and Relationship of Structure to Activity”&lt;/a&gt;&amp;nbsp;&lt;a href="#fnref:spiro" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id="fn:ACM"&gt;
      &lt;p&gt;&lt;a href="http://dl.acm.org/citation.cfm?id=512945"&gt;On the ACM digital library&lt;/a&gt;&amp;nbsp;&lt;a href="#fnref:ACM" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id="fn:English"&gt;
      &lt;p&gt;You have a set. You have a binary operation on that set, “meet”, which takes two objects in the set as arguments and returns a third object in the set. The order of arguments to meet is not important (commutativity), and you can also rearrange groupings freely (associativity). If the two objects are the same, their meet is that same object (idempotency). There are examples later.&amp;nbsp;&lt;a href="#fnref:English" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id="fn:pessimism"&gt;
      &lt;p&gt;The algorithm generally proceeds from an incorrectly optimistic initial state down to harder-to-optimize reality.&amp;nbsp;&lt;a href="#fnref:pessimism" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id="fn:funcall"&gt;
      &lt;p&gt;This is not actually true in general: We can define a function like &lt;code&gt;(labels ((foo () #'foo)) ...)&lt;/code&gt; that returns itself, or worse. But in HIR, recursive functions are currently implemented by putting the function in a cell (keep reading this post for more on those) which is over by the function. Since the analysis considers being written into a cell an escape, any function that returns itself will be marked as escaping for other reasons.&amp;nbsp;&lt;a href="#fnref:funcall" class="reversefootnote"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</content>
    <summary type="html">
&lt;p&gt;Been a while. Life is busying.&lt;/p&gt;

&lt;p&gt;I got a part time job writing a Lisp compiler, so I’m going to talk about that.&lt;/p&gt;

&lt;p&gt;This post might be hard to understand if you do not program. Or if you do. There’s a fair amount of background required.&lt;/p&gt;

&lt;div class='read-more'&gt;&lt;a href='/posts/kildall.html'&gt;Continue reading &amp;rsaquo;&lt;/a&gt;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <id>tag:bike.github.io,2016-08-10:/posts/dirt-simple-de.html</id>
    <title type="html">Dirt simple DE</title>
    <published>2016-08-10T03:52:57Z</published>
    <updated>2016-08-10T03:52:57Z</updated>
    <link rel="alternate" href="https://bike.github.io/posts/dirt-simple-de.html"/>
    <content type="html">
&lt;p&gt;I’m working through the exercises of a dynamics textbook for lack of worse things to do.&lt;/p&gt;

&lt;p&gt;Dynamics is pretty neat. It is a part of mathematics useful for modeling approximately continuous physical processes. This is analogous to computers, which are useful for modeling discontinuous processes. (I’m going to write about that analogy later, but it’s a subject that requires a lot of precision.) If you’re used to computer models, which tend to be lengthy series of pretty opaque numeric operations possibly written in some obscure language like IDL, the seeming terseness of most dynamic models can be a bit surprising. Where do all these constants come from? How can you draw important conclusions without even having values?&lt;/p&gt;

&lt;p&gt;Well, that’s what I thought when I began learning dynamics, anyway. As it turns out, this is how it works because it’s pretty easy to invent a dynamic model, and easy to describe, and in some cases determine, their qualitative behavior.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id="what-is-dynamics"&gt;What is dynamics?&lt;/h2&gt;

&lt;p&gt;Dynamics was invented by Newton*. He wanted to know how physical objects, like planets, move. Naturally this means you want to think about the positions of planets. Pretty obviously you might also be concerned with their velocity, that is the &lt;em&gt;rate&lt;/em&gt; at which their positions change, and maybe even their acceleration, the &lt;em&gt;rate&lt;/em&gt; at which their velocities change. Not infrequently, velocities and acclerations depend on positions, and so on. Newton’s law of gravitation, for example, tells you that the acceleration due to gravity of an object depends on the inverse square of its distance (relative position) to whatever object is exerting a gravitational pull. You can write this down something like&lt;/p&gt;

&lt;p&gt;d²r/dt² = k/r²&lt;/p&gt;

&lt;p&gt;which is to say, the rate of the rate of change of r equals k (a constant of proportionality) times the inverse square of r. This equation is called a “differential equation” because it relates a quantity (position) to its rates of change, or “derivatives” (d²r/dt²).&lt;/p&gt;

&lt;p&gt;This is dynamics. You have rates of change for one or more variables in terms of those variables, and you want to know how those variables actually change - the actual path of the planet, or whatever. Those variables are functions of one independent variable, usually “time”: r(t) = something. (Multiple independent variables takes you to partial differential equations, which are rather more complicated.)&lt;/p&gt;

&lt;h2 id="basic-population-growth"&gt;Basic population growth&lt;/h2&gt;

&lt;p&gt;Every text on dynamics starts with modeling population growth. If you understand this you can skip the first lecture of any class on the subject.&lt;/p&gt;

&lt;p&gt;Say you want to know how the population of an animal species changes over time. You could spend fifty years trapping hares to get samples of the total population, or if you have a reliable human census, use that. In either case you get &lt;em&gt;specifics&lt;/em&gt;. If a meteor struck and killed large parts of the population in the period your data covers, you’re going to see unusual population changes and it’s going to be difficult to extrapolate the future unless you drop a meteor later yourself. You need some kind of theory to explain the numbers you see.&lt;/p&gt;

&lt;p&gt;And hey, trapping is hard, so why not just start there?&lt;/p&gt;

&lt;p&gt;You simplify things greatly. Say you only want to deal with one variable, the population itself. Famines and wars and such are right out. So you might write out&lt;/p&gt;

&lt;p&gt;dP/dt = f(P)&lt;/p&gt;

&lt;p&gt;which is to say that the rate that P, the population, changes, is some arbitrary function of only P itself.&lt;/p&gt;

&lt;p&gt;That’s too vague to solve. You must make further simplifications. You can suppose then that the function f is linear. So, for instance, if you have two populations, and one is twice as large as the other, you would suppose that the larger population grows twice as fast, because there are about twice as many animals/couples reproducing.&lt;/p&gt;

&lt;p&gt;You can also suppose that f(0) = 0, i.e. that if everybody is dead they will not be coming back. Sad!&lt;/p&gt;

&lt;p&gt;These two assumptions together reduce f to being a multiplication by a constant, so your population growth equation is&lt;/p&gt;

&lt;p&gt;dP/dt = cP&lt;/p&gt;

&lt;p&gt;Behold. A model. You can get a curve out of this, P(t) = P(0)exp(ct), and graph it and watch population grow. Regardless of what c or P(0), you will note that P “accelerates”, and grows faster as it grows (as expected from our equation). This is “exponential growth”.&lt;/p&gt;

&lt;p&gt;It’s simple, very super simple, but it’s enough of a model that you can derive some interesting things like Maltusian catastrophes or &lt;a href="http://stochastictalk.blogspot.com/2016/05/karl-marx-at-sunset-of-classical.html"&gt;Marxism&lt;/a&gt; with some more work.&lt;/p&gt;

&lt;p&gt;Of course, you also just made it up, so probably do some empirical validation before you start crowing about surplus population and well yeah.&lt;/p&gt;

&lt;h2 id="carrying-capacity"&gt;Carrying capacity&lt;/h2&gt;

&lt;p&gt;Now let’s say you do some empirical work, maybe go out and work for Hudson’s Bay Company but don’t make enough money on hare furs to quit your modeling job, so you go back to the grindstone.&lt;/p&gt;

&lt;p&gt;In your observations you’ve noticed that the environments populations of animals live in have what you call a “carrying capacity”. If the population in an area is above this “capacity” level, there is not enough food, space for burrows, whatever, and the population dies off. Below the carrying capacity, the population does still grow, but it slows down as it approaches the capacity. You want to modify the above population growth equation with this capacity, call it a constant, K                             .&lt;/p&gt;

&lt;p&gt;You want positive growth P &amp;lt; K and negative growth (death) for P &amp;gt; K. Negative growth just means dP/dt is negative, so one way to do this would be to multiply the existing equation by a number that’s negative only when P &amp;gt; K:&lt;/p&gt;

&lt;p&gt;dP/dt = cP(K - P)&lt;/p&gt;

&lt;p&gt;This sort of works, but has the odd consequence that the growth rate can depend pretty directly on the value of K. E.g., a very low (i.e., the limit as P goes to zero) population in an environment with a K of 10000 will grow about a hundred times faster than one in an environment with a K of 100. This doesn’t exactly fit our ideas of how populations grow, since that higher K could just mean, say, a hundred times more area, for a species that doesn’t even travel around that much.&lt;/p&gt;

&lt;p&gt;Maybe what we want to say is that as K increases to infinity, we recover the original simple dP/dt = cP. Having new models be conservative extensions to existing ones is a useful tactic.&lt;/p&gt;

&lt;p&gt;So instead we can work with the ratio, P/K. P/K is greater than one when P &amp;gt; K, and less than one when P &amp;lt; K, so:&lt;/p&gt;

&lt;p&gt;dP/dt = cP(1 - P/K)&lt;/p&gt;

&lt;p&gt;and when K approaches infinity (or as P approaches zero), the parenthetical term approaches 1, giving us back our original model.&lt;/p&gt;

&lt;h2 id="explicit-solutions"&gt;“Explicit” solutions&lt;/h2&gt;

&lt;p&gt;New model, great. Can we write out an equation to graph, like we did for dP/dt = cP? It turns out that we’re out of luck there, but that may not be so bad.&lt;/p&gt;

&lt;p&gt;You can “explicitly” “solve” any one dimensional differential equation by separation of variables. The solution of dy/dx = F(y) is&lt;/p&gt;

&lt;p&gt;&lt;img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/689ac8cba86b425a32c080e57727b90611f8068b" alt="one-dimensional DE solution" /&gt;&lt;/p&gt;

&lt;p&gt;That is, you can find x as a function of y, but not y as a function of x, at least immediately. It’s a bit odd. If you include y(0) as the bottom limit of integration, you can find x(t) and eliminate the integration constant.&lt;/p&gt;

&lt;p&gt;For the original dP/dt = cP, for instance, we’d integrate 1/(cP), giving us t(P) = log(P(t))/c - log(P(0))/c. Do some algebra and you’ll see that this implies log(P(t)) = ct + log(P(0)); exponentiate both sides and P(t) = P(0)exp(ct) as previously mentioned.&lt;/p&gt;

&lt;p&gt;Inverting the function of time cannot always be done. If we had dx/dt = -x/(1+x²), for instance, we would find that “explicitly”, log(x) + (1/2)x² = -t + log(x(0)) + (1/2)(x(0))², and good luck with that. And of course, sometimes the antiderivative might not be expressible in elementary functions to begin with.&lt;/p&gt;

&lt;p&gt;But that’s not so important, because given just the differential equation(s), you can solve “by quadratures”, also known as “by numerical integration”. This is quite a common thing to do, and hey, if you’re graphing an exponential function on your computer it’s probably doing &lt;em&gt;something&lt;/em&gt; iteratively.&lt;/p&gt;

&lt;p&gt;The interesting thing here is that dynamic models can very easily, or even often, result in unfamiliar functions.&lt;/p&gt;

&lt;h2 id="land-use"&gt;Land use&lt;/h2&gt;

&lt;p&gt;Now let’s really complicate this model. The following is a set of equations from &lt;a href="http://dx.doi.org/10.1126/science.277.5325.515"&gt;Dobson, Bradshaw, and Baker 1997&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let’s restrict to humans, and say we want to do this for a specific reason: we’re concerned about farming ecology (e.g. slash-and-burn is a big issue in South America, etc.). So we add a variable, A, to represent the agricultural land area. We further assume that the carrying capacity is proportional to A (i.e. twice as much farmland = twice as much capacity), so&lt;/p&gt;

&lt;p&gt;dP/dt = cP(1-P/(hA))&lt;/p&gt;

&lt;p&gt;The amount of farmland fluctuates as well. To model land use, we divide all land up into three kinds: farmland (A), forest (F), and unused or “other” (U). Farmland can be increased by people converting unused land or forest into farms, and decreased by farms being abandoned or the land being overused. We make up some constants, and&lt;/p&gt;

&lt;p&gt;dA/dt = dPF + bU - aA&lt;/p&gt;

&lt;p&gt;The term for converting forests involves an additional factor for the population - people will be more motivated to burn down forest for land when they need more food. You could put that factor on the conversion from unused land as well, but it’s nice to reduce the number of nonlinear terms, and ecologists are presumably more preoccupied with forests.&lt;/p&gt;

&lt;p&gt;Forest grows over unused land. Call the constant for that s, and you get two more equations for area changes:&lt;/p&gt;

&lt;p&gt;dF/dt = sU - dPF
dU/dt = aA - (b+s)U&lt;/p&gt;

&lt;p&gt;So we have four differential equations total, which are all linked.&lt;/p&gt;

&lt;p&gt;An important thing to note is that the total land, P+A+F, is conserved. Which makes sense, you can’t just make more land. You can observe this is true in the model by seeing that d(P+A+F)/dt = dP/dt + dA/dt + dF/dt = 0.&lt;/p&gt;

&lt;h2 id="long-term-behavior"&gt;Long term behavior&lt;/h2&gt;

&lt;p&gt;Earlier I mentioned that exponential growth, well, grows. This is obviously not true of every dynamical system, but there are only so many ways a dynamic system can “end” - only so many things an f(t) can be as t goes to infinity.&lt;/p&gt;

&lt;p&gt;Firstly it can approach a constant (which may be infinity). This happens with normal exponential growth if P(0) = 0; P(t) = 0 forever, because no more population is going to be created from nothing. It also happens, a bit more subtly, in the carrying capacity version; if P/K = 1 (so P = K), dP/dt equals zero, so P just stays there. This is called an equilibrium state.&lt;/p&gt;

&lt;p&gt;You find an equilibrium state by setting all the rates of change to zero, so that nothing moves. This may be easier said than done, for complicated systems, but it’s workable for the land use thing here.&lt;/p&gt;

&lt;p&gt;dP/dt = 0 = cP(1-P/(hA)), so either P = 0 or P = hA. For P = 0, dF/dt = 0 = sU - dPF shows that sU = dPF, but P = 0, so U = 0. dA/dt = 0 = dPF + bU - aA then shows A is zero as well, and F is unconstrained; so everybody being dead and all the world (however large it is) being forest is an equilibrium. If P = hA, sU = dPF = dhAF. From dU/dt, aA = (b+s)U, and substituting back sU = dh(1/a)(b+s)UF, so F = as/(dh(b+s)); the other values can be worked out similarly. So there are two equilibria.&lt;/p&gt;

&lt;p&gt;There could additionally be cycles, some set of values that repeatedly evolves back to itself. These are much harder to find, especially in higher dimensions; I vaguely remember a story about a Russian mathematics professor passing out to each of his students a random quadratic DE systems and telling them to find any limit cycles, and getting no results.&lt;/p&gt;

&lt;p&gt;And since it’s (bigger than) three dimensional, it can additionally have toruses, and strange attractors, and all that.&lt;/p&gt;

&lt;p&gt;But at least we got a model.&lt;/p&gt;

&lt;p&gt;*: Leibniz invented calculus independently, but I don’t know what he used it for. There’s a lot of important work Newton and Leibniz could use to build calculus, like Fermat’s (of theorem fame) adequality. Newton, however, built a whole theory of differential equations (or “fluxions”), so I’m blaming him. They were all hella smart dudes regardless.&lt;/p&gt;
</content>
    <summary type="html">
&lt;p&gt;I’m working through the exercises of a dynamics textbook for lack of worse things to do.&lt;/p&gt;

&lt;p&gt;Dynamics is pretty neat. It is a part of mathematics useful for modeling approximately continuous physical processes. This is analogous to computers, which are useful for modeling discontinuous processes. (I’m going to write about that analogy later, but it’s a subject that requires a lot of precision.) If you’re used to computer models, which tend to be lengthy series of pretty opaque numeric operations possibly written in some obscure language like IDL, the seeming terseness of most dynamic models can be a bit surprising. Where do all these constants come from? How can you draw important conclusions without even having values?&lt;/p&gt;

&lt;p&gt;Well, that’s what I thought when I began learning dynamics, anyway. As it turns out, this is how it works because it’s pretty easy to invent a dynamic model, and easy to describe, and in some cases determine, their qualitative behavior.&lt;/p&gt;

&lt;div class='read-more'&gt;&lt;a href='/posts/dirt-simple-de.html'&gt;Continue reading &amp;rsaquo;&lt;/a&gt;&lt;/div&gt;</summary>
  </entry>
  <entry>
    <id>tag:bike.github.io,2016-07-28:/posts/about.html</id>
    <title type="html">About</title>
    <published>2016-07-28T23:59:20Z</published>
    <updated>2016-07-28T23:59:20Z</updated>
    <link rel="alternate" href="https://bike.github.io/posts/about.html"/>
    <content type="html">
&lt;p&gt;I am a computational neuroscience student. As of yet, I have no name.&lt;/p&gt;

&lt;p&gt;This blog has no particular subject, but I am most predisposed to write about science, as that is the kind of writing I am best at. I have other interests, such as history, but expect less content in this area.&lt;/p&gt;

&lt;p&gt;I have no personality and hate being identified.&lt;/p&gt;
</content>
    <summary type="html">
&lt;p&gt;I am a computational neuroscience student. As of yet, I have no name.&lt;/p&gt;

&lt;p&gt;This blog has no particular subject, but I am most predisposed to write about science, as that is the kind of writing I am best at. I have other interests, such as history, but expect less content in this area.&lt;/p&gt;

&lt;p&gt;I have no personality and hate being identified.&lt;/p&gt;
</summary>
  </entry>
  <entry>
    <id>tag:bike.github.io,2016-07-28:/posts/organ-complexity.html</id>
    <title type="html">Kidneys are hard</title>
    <published>2016-07-28T20:47:51Z</published>
    <updated>2016-07-28T20:47:51Z</updated>
    <link rel="alternate" href="https://bike.github.io/posts/organ-complexity.html"/>
    <content type="html">
&lt;p&gt;Conversation on twitter:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758704690586460160"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; random thought regarding http://arstechnica.com/science/2016/07/the-man-who-got-the-first-double-hand-transplant-wishes-he-hadnt/&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758704840360898562"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; originally, people thought human tech would be superior to transplants, etc, because Obviously Tech Is Better, sci-fi, etc&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758704953242161152"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; then sci-fi types started to realize that biology was really good at what it does and human replacements were laughable try-hards&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758705029670776833"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; but the problem is we have no freaking clue how the biological stuff works, while we do understand our shitty replacements&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758706138061811714"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; so…. we may end up going full circle back to cyborgs because we suck at biology?&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/yaodema/status/758712622309109760"&gt;&amp;lt;yaodema&amp;gt;&lt;/a&gt; And because prostheses are getting way better. Transplants are terrible, nerve damage is hard to fix, etc.&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758713108487507970"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; exactly. even if human organs are way better than artificial ones, we don’t understand them enough to use and fix them&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is sorta true. Biology is hard, especially when you want to validate your understanding by actually making functioning things. Transplants are, as in the linked article, kind of hit or miss, and require immunosuppressants and antibiotics (for surgery), which is a bit like having to pump a factory full of chlorine gas before you can fix anything. But I don’t know if artificial replacements are so much of an improvement, at least as concerns understanding.&lt;/p&gt;

&lt;p&gt;Large parts of the body are effectively irreplaceable for the forseeable future - most obviously, the immune and nervous systems*, exactly the ones an implant most needs to deal with. Given that the implant designer can’t design the entire body, the first reason implants (or, it should be said, transplants) are so difficult to design/perform is that their interactions with the rest of the body, especially these systems, are difficult to control. It’s not that hard to make a pump the size of a heart, but it’s hard to make one that hooks up to the cardiovascular system without something dying, and, at present, impossible to make one that properly responds to nervous signals.&lt;/p&gt;

&lt;p&gt;The difficulty of course changes depending on what is being replaced. We can make legs now that are better than real ones in a few aspects. Artificial hands can reach and grasp and are beginning to provide haptic feedback. Hearts are, as mentioned, regulatorily isolated, and only last a few years. Ears are only good enough to make it easier to read lips.&lt;/p&gt;

&lt;p&gt;The problem of interaction is one of both physics and understanding. We lack understanding of what nervous signals mean: this is something we can improve and are improving on. (It’s something I’d like to help improve.)&lt;/p&gt;

&lt;p&gt;But we also lack the &lt;em&gt;physical ability&lt;/em&gt; to make good connections. When you insert a neuroprosthetic into somebody, you maneuever a wire or probe into an area that has neurons in it. The probe then mediates some electrical stimulation - emits or sucks in nearby electrons, which hopefully alters the local potential enough that neurons nearby change their behavior in a way close to what we would like. It’s hard to understate how crappy this is. The probe has to be designed to do minimal damage to living tissue - damage that’s quite easy to do, since living tissue isn’t great with electric shocks - as well as to survive itself in an environment few iridium wires have ever gone before. Even when this is accomplished, its actual ability to stimulate is not great, because it can only manipulate the outside potentials.&lt;/p&gt;

&lt;p&gt;Humans have, in fact, designed “artificial cochleas” better than any of the signal processing in cochlear implants; but they lack the ability to effectively communicate with spiral ganglion cells, so nobody’s getting one in their skull any time soon.&lt;/p&gt;

&lt;p&gt;But that’s all still, more or less, a technological problem, something we will maybe solve in the future, ushering in an era of slightly less laughable replacements.&lt;/p&gt;

&lt;p&gt;So let’s ask: why is it that biology is hard, and computers are easy?&lt;/p&gt;

&lt;p&gt;The blithe answer is evolution. There has been no selection pressure for humans to evolve JTAG ports for debugging, and so we lack them. There has been no selection pressure to make open heart surgery easy, so it’s newer than computers despite that we’ve had all the tools to open ribcages for quite a while. There has been no selection pressure to make kidneys hot-swappable, so we have to bother with immunosuppressants and all that crap.&lt;/p&gt;

&lt;p&gt;This is true but doesn’t really answer anything. There might be &lt;em&gt;reasons&lt;/em&gt; that the body is as hard to operate on as it is; actual design considerations that could come up even when an enterprising neuroprosthetist decides to redesign humanity from scratch, piece by piece.&lt;/p&gt;

&lt;p&gt;When you, or a robot, jogs, on your so-mechanically-interesting legs, the most obvious thing to happen is that the control system (brain, CPU) sends signals to the actuators (muscles, motors) to move in some jogging pattern. This is a process reasonably well understood by roboticists, and robots can successfully walk. The second most obvious thing to happen is that less famous parts of actuators, with obscure names like “nuclear bag fibers” or “Hall effect sensors”, send signals back to and through the control system so that the system as a whole can be adjsted to walk better. Roboticists have, as far as I know, a pretty good understanding of this too, and so Boston Dynamics machines can walk on rubble.&lt;/p&gt;

&lt;p&gt;The less obvious thing to happen, in humans and I don’t think robots, is the sympathetic response. Your brain sends signals down your vagus nerve that hit most organs. Your heart beats faster: obviously. Your lungs reorient to take in more air: no surprise. Your pupils dilate: uh. Your intestines’ autonomic peristalsis is inhibited: guess that makes sense. Smooth muscles around blood vessels contract or relax depending on whether they feed your gastrointestinal system or your extremities: okay. Your kidneys secrete more renin: what?&lt;/p&gt;

&lt;p&gt;Unsurprisingly, all this is part of a “design” to regulate energy usage, since there’s not much call to continue digesting lunch while you’re running from the jabberwock. But practically speaking, it means every part of the body has to somehow be informed about a bunch of seemingly irrelevant crap. Kidneys are not just filters: they react to sympathetic innervation, as well as water and sodium levels, and &lt;a href="https://en.wikipedia.org/wiki/Renin%E2%80%93angiotensin_system"&gt;all this complex stuff that inexplicably involves the lungs&lt;/a&gt;. Pretty much every organ is like this. Even the gallbladder, probably, even though it’s mostly just a bag.&lt;/p&gt;

&lt;p&gt;So if you want a replacement organ, either you have to fit all those complex interactions into your implant, or you just focus on one thing and abandon the rest. That is to say, replacement organs are not just laughable try-hards because it’s hard to make a small pump/filter/whatever, they’re laughable try-hards because they can’t do everything the original can do. Artificial hearts (and, again, transplants), as mentioned, don’t receive vagus innervation and only sometimes** even change their flow rate in response to blood pressure. Dialysis machines are huge and generally make you sit still. Etc.&lt;/p&gt;

&lt;p&gt;You may think that this is not so bad. That you can roll this up as a necessary sacrifice in order that we can have some understanding of what the hell is happening. That we can just have our artificial organs do one thing, and do it well.&lt;/p&gt;

&lt;p&gt;Does &lt;a href="https://en.wikipedia.org/wiki/Unix_philosophy"&gt;that&lt;/a&gt; even work for computers? If you have used a computer for very long, you probably know that the answer is no. Eventually you want emacs or Firefox or to sprint without your muscles slowly dying of oxygen starvation, and suddenly you don’t understand anything. Listen: when I leave Firefox on for a long time, YouTube videos don’t play smoothly. Do I know what that happens? No. Do I expect to fix it? Ha ha no. Do I expect anybody to fix it? Still no, because I know that the problem is probably a consequence of complex interactions between the memory allocator, SpiderMonkey, systemd, Linux syscalls, my zshrc, my Steam community profile, electromagnetic emanations from the nearby power substation, and possibly even the CPU at some level. I have as much understanding of the problem as I do of cancer. The symptom is obvious, but for the cause I’m left thinking stupid things like “maybe I should upgrade” or “doesn’t red wine help with that?”&lt;/p&gt;

&lt;p&gt;I think that humanity has not yet come up with a good way to design this kind of system. There might not even be one, for standards of “good” allowing maintenance like you can do on simpler machinery. Consider how hard it is to get a video game working well on Linux, and then imagine how hard it will be to install a Weyland-Yutani lymph node in a body that has original components, a Betacel pacemaker, and kidneys of two different brands.&lt;/p&gt;

&lt;p&gt;This isn’t to say that implants are inherently useless, or won’t get better, or anything like that. I just think that a complex system like the body, individual parts of it, or even my desktop computer, is going to be more-or-less inherently hard to understand.&lt;/p&gt;

&lt;p&gt;*: This is a whole other post&lt;/p&gt;

&lt;p&gt;**: Wikipedia says that CARMAT, developed in 2008, is the first to do this, but I admit I don’t know much about artificial heart design and this may be wrong.&lt;/p&gt;
</content>
    <summary type="html">
&lt;p&gt;Conversation on twitter:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758704690586460160"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; random thought regarding http://arstechnica.com/science/2016/07/the-man-who-got-the-first-double-hand-transplant-wishes-he-hadnt/&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758704840360898562"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; originally, people thought human tech would be superior to transplants, etc, because Obviously Tech Is Better, sci-fi, etc&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758704953242161152"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; then sci-fi types started to realize that biology was really good at what it does and human replacements were laughable try-hards&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758705029670776833"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; but the problem is we have no freaking clue how the biological stuff works, while we do understand our shitty replacements&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758706138061811714"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; so…. we may end up going full circle back to cyborgs because we suck at biology?&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/yaodema/status/758712622309109760"&gt;&amp;lt;yaodema&amp;gt;&lt;/a&gt; And because prostheses are getting way better. Transplants are terrible, nerve damage is hard to fix, etc.&lt;/p&gt;

  &lt;p&gt;&lt;a href="https://twitter.com/FioraAeterna/status/758713108487507970"&gt;&amp;lt;Fiora&amp;gt;&lt;/a&gt; exactly. even if human organs are way better than artificial ones, we don’t understand them enough to use and fix them&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is sorta true. Biology is hard, especially when you want to validate your understanding by actually making functioning things. Transplants are, as in the linked article, kind of hit or miss, and require immunosuppressants and antibiotics (for surgery), which is a bit like having to pump a factory full of chlorine gas before you can fix anything. But I don’t know if artificial replacements are so much of an improvement, at least as concerns understanding.&lt;/p&gt;

&lt;p&gt;Large parts of the body are effectively irreplaceable for the forseeable future - most obviously, the immune and nervous systems*, exactly the ones an implant most needs to deal with. Given that the implant designer can’t design the entire body, the first reason implants (or, it should be said, transplants) are so difficult to design/perform is that their interactions with the rest of the body, especially these systems, are difficult to control. It’s not that hard to make a pump the size of a heart, but it’s hard to make one that hooks up to the cardiovascular system without something dying, and, at present, impossible to make one that properly responds to nervous signals.&lt;/p&gt;

&lt;p&gt;The difficulty of course changes depending on what is being replaced. We can make legs now that are better than real ones in a few aspects. Artificial hands can reach and grasp and are beginning to provide haptic feedback. Hearts are, as mentioned, regulatorily isolated, and only last a few years. Ears are only good enough to make it easier to read lips.&lt;/p&gt;

&lt;p&gt;The problem of interaction is one of both physics and understanding. We lack understanding of what nervous signals mean: this is something we can improve and are improving on. (It’s something I’d like to help improve.)&lt;/p&gt;

&lt;p&gt;But we also lack the &lt;em&gt;physical ability&lt;/em&gt; to make good connections. When you insert a neuroprosthetic into somebody, you maneuever a wire or probe into an area that has neurons in it. The probe then mediates some electrical stimulation - emits or sucks in nearby electrons, which hopefully alters the local potential enough that neurons nearby change their behavior in a way close to what we would like. It’s hard to understate how crappy this is. The probe has to be designed to do minimal damage to living tissue - damage that’s quite easy to do, since living tissue isn’t great with electric shocks - as well as to survive itself in an environment few iridium wires have ever gone before. Even when this is accomplished, its actual ability to stimulate is not great, because it can only manipulate the outside potentials.&lt;/p&gt;

&lt;p&gt;Humans have, in fact, designed “artificial cochleas” better than any of the signal processing in cochlear implants; but they lack the ability to effectively communicate with spiral ganglion cells, so nobody’s getting one in their skull any time soon.&lt;/p&gt;

&lt;p&gt;But that’s all still, more or less, a technological problem, something we will maybe solve in the future, ushering in an era of slightly less laughable replacements.&lt;/p&gt;

&lt;p&gt;So let’s ask: why is it that biology is hard, and computers are easy?&lt;/p&gt;

&lt;p&gt;The blithe answer is evolution. There has been no selection pressure for humans to evolve JTAG ports for debugging, and so we lack them. There has been no selection pressure to make open heart surgery easy, so it’s newer than computers despite that we’ve had all the tools to open ribcages for quite a while. There has been no selection pressure to make kidneys hot-swappable, so we have to bother with immunosuppressants and all that crap.&lt;/p&gt;

&lt;p&gt;This is true but doesn’t really answer anything. There might be &lt;em&gt;reasons&lt;/em&gt; that the body is as hard to operate on as it is; actual design considerations that could come up even when an enterprising neuroprosthetist decides to redesign humanity from scratch, piece by piece.&lt;/p&gt;

&lt;p&gt;When you, or a robot, jogs, on your so-mechanically-interesting legs, the most obvious thing to happen is that the control system (brain, CPU) sends signals to the actuators (muscles, motors) to move in some jogging pattern. This is a process reasonably well understood by roboticists, and robots can successfully walk. The second most obvious thing to happen is that less famous parts of actuators, with obscure names like “nuclear bag fibers” or “Hall effect sensors”, send signals back to and through the control system so that the system as a whole can be adjsted to walk better. Roboticists have, as far as I know, a pretty good understanding of this too, and so Boston Dynamics machines can walk on rubble.&lt;/p&gt;

&lt;p&gt;The less obvious thing to happen, in humans and I don’t think robots, is the sympathetic response. Your brain sends signals down your vagus nerve that hit most organs. Your heart beats faster: obviously. Your lungs reorient to take in more air: no surprise. Your pupils dilate: uh. Your intestines’ autonomic peristalsis is inhibited: guess that makes sense. Smooth muscles around blood vessels contract or relax depending on whether they feed your gastrointestinal system or your extremities: okay. Your kidneys secrete more renin: what?&lt;/p&gt;

&lt;p&gt;Unsurprisingly, all this is part of a “design” to regulate energy usage, since there’s not much call to continue digesting lunch while you’re running from the jabberwock. But practically speaking, it means every part of the body has to somehow be informed about a bunch of seemingly irrelevant crap. Kidneys are not just filters: they react to sympathetic innervation, as well as water and sodium levels, and &lt;a href="https://en.wikipedia.org/wiki/Renin%E2%80%93angiotensin_system"&gt;all this complex stuff that inexplicably involves the lungs&lt;/a&gt;. Pretty much every organ is like this. Even the gallbladder, probably, even though it’s mostly just a bag.&lt;/p&gt;

&lt;p&gt;So if you want a replacement organ, either you have to fit all those complex interactions into your implant, or you just focus on one thing and abandon the rest. That is to say, replacement organs are not just laughable try-hards because it’s hard to make a small pump/filter/whatever, they’re laughable try-hards because they can’t do everything the original can do. Artificial hearts (and, again, transplants), as mentioned, don’t receive vagus innervation and only sometimes** even change their flow rate in response to blood pressure. Dialysis machines are huge and generally make you sit still. Etc.&lt;/p&gt;

&lt;p&gt;You may think that this is not so bad. That you can roll this up as a necessary sacrifice in order that we can have some understanding of what the hell is happening. That we can just have our artificial organs do one thing, and do it well.&lt;/p&gt;

&lt;p&gt;Does &lt;a href="https://en.wikipedia.org/wiki/Unix_philosophy"&gt;that&lt;/a&gt; even work for computers? If you have used a computer for very long, you probably know that the answer is no. Eventually you want emacs or Firefox or to sprint without your muscles slowly dying of oxygen starvation, and suddenly you don’t understand anything. Listen: when I leave Firefox on for a long time, YouTube videos don’t play smoothly. Do I know what that happens? No. Do I expect to fix it? Ha ha no. Do I expect anybody to fix it? Still no, because I know that the problem is probably a consequence of complex interactions between the memory allocator, SpiderMonkey, systemd, Linux syscalls, my zshrc, my Steam community profile, electromagnetic emanations from the nearby power substation, and possibly even the CPU at some level. I have as much understanding of the problem as I do of cancer. The symptom is obvious, but for the cause I’m left thinking stupid things like “maybe I should upgrade” or “doesn’t red wine help with that?”&lt;/p&gt;

&lt;p&gt;I think that humanity has not yet come up with a good way to design this kind of system. There might not even be one, for standards of “good” allowing maintenance like you can do on simpler machinery. Consider how hard it is to get a video game working well on Linux, and then imagine how hard it will be to install a Weyland-Yutani lymph node in a body that has original components, a Betacel pacemaker, and kidneys of two different brands.&lt;/p&gt;

&lt;p&gt;This isn’t to say that implants are inherently useless, or won’t get better, or anything like that. I just think that a complex system like the body, individual parts of it, or even my desktop computer, is going to be more-or-less inherently hard to understand.&lt;/p&gt;

&lt;p&gt;*: This is a whole other post&lt;/p&gt;

&lt;p&gt;**: Wikipedia says that CARMAT, developed in 2008, is the first to do this, but I admit I don’t know much about artificial heart design and this may be wrong.&lt;/p&gt;
</summary>
  </entry>
  <entry>
    <id>tag:bike.github.io,2016-07-21:/posts/first-post.html</id>
    <title type="html">First post</title>
    <published>2016-07-21T00:43:09Z</published>
    <updated>2016-07-21T00:43:09Z</updated>
    <link rel="alternate" href="https://bike.github.io/posts/first-post.html"/>
    <content type="html">
&lt;p&gt;Setting up a blog is harder than I’d thought.&lt;/p&gt;
</content>
    <summary type="html">
&lt;p&gt;Setting up a blog is harder than I’d thought.&lt;/p&gt;
</summary>
  </entry>
</feed>

